<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Real-time 3D reconstruction and 6-DOF tracking with an Event Camera</title>
    <link href="/2024/11/21/Real-time-3D-reconstruction-and-6-DOF-tracking-with-an-Event-Camera/"/>
    <url>/2024/11/21/Real-time-3D-reconstruction-and-6-DOF-tracking-with-an-Event-Camera/</url>
    
    <content type="html"><![CDATA[<h2 id="摘要–"><a href="#摘要–" class="headerlink" title="摘要–"></a>摘要–</h2><p>第一个仅基于事件相机的6自由度位子估计和3D重建的方法<br>核心思想是3个交错的概率滤波器解决SLAM中的相机运动，场景对数强度梯度，场景逆深度<br>通过纯时间输入中输出实时，高带宽，6DoF摄像机轨迹，一个或多个相关联的关键帧的场景深度图</p><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><h3 id="Event-Based-Cameras"><a href="#Event-Based-Cameras" class="headerlink" title="Event-Based Cameras"></a>Event-Based Cameras</h3><p>通过对于每一个像素的位置、极性和微秒级别时间戳的记录的特性，克服依赖于传统的成像传感器的高延迟，低动态范围和高功耗<br>data with conventional intensity frames (DAVIS)。ATIS 以DAVIS和ATIS为基准，提出了其存在的问题：</p><ol><li>持续运动中它们可能并不有用。</li><li>损耗了纯基于时间的数据流的最佳信息效率</li></ol><p>因此提出了不依靠于标准图像帧的方案</p><h3 id="Relate-Work"><a href="#Relate-Work" class="headerlink" title="Relate Work"></a>Relate Work</h3><ul><li><p>Cook等[ 7 ]提出了一个交互网络，在估计全局旋转相机运动的同时，解释一系列事件流，以恢复场景的不同视觉估计”地图”，如强度、梯度和光流。<br>  最近，Bardow等人[ 1 ]提出了一种使用事件相机的光流和强度估计方法，该方法允许任意相机运动和动态场景。</p></li><li><p>与本文最相关的工作是Kim等人[ 12 ]提出的基于概率滤波的简化SLAM系统，该系统在跟踪全局相机旋转的同时估计空间梯度，然后将其整合以重建高质量和高动态范围的平面场景</p></li><li><p>他们的方法与我们的方法具有相似的整体概念，即多个相互作用的概率滤波器，但仅限于纯旋转相机运动和全景图重建。同时，由于其跟踪算法中使用的粒子滤波的计算复杂性，它也不是完全实时的<br>所以提出的核心思想就是：一旦相机开始平移，如果两个像素有相同的强度梯度，靠近相机的像素比远的哪一个移动的更快和传递的事件更多。<br>利用这一机制进行反解深度</p></li></ul><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><ul><li>3个交织的概率滤波器，第一个负责追踪全局的6dof相机运动，第二种估计关键帧图像中的对数强度梯度，这种表示也被并行地升级为全图像的强度图，第三个负责反解关键帧的深度。</li><li>将建图分为两个部分：梯度和逆深度</li></ul><h3 id="预先工作"><a href="#预先工作" class="headerlink" title="预先工作"></a>预先工作</h3><p>定义事件: u,v 是像素的位置<br>$$ e(u, v) &#x3D; (u, v, p, t)^T $$ </p><h3 id="事件相机6自由度追踪"><a href="#事件相机6自由度追踪" class="headerlink" title="事件相机6自由度追踪"></a>事件相机6自由度追踪</h3><ol><li>基于事件的摄像机6 - Dof跟踪<br><br>利用李群和李代数之间的指数和对数映射，其基本思想是找到(假设当前的测井强度和反演深度估计是正确的)这个相机位姿，它最能预测一个与刚刚接收到的事件一致的对数强度变化<br><br><strong>事件预测</strong><br>使用6 - DoF (平移和旋转)连续位置运动模型进行运动预测；预测的方差与时间间隔成正比<br><strong>事件更新</strong><br>使用射线三角相交检测进行求解焦点之间的对数强度差，重建一个具有逆深度的类图像对数强度关键帧。</li></ol><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><ul><li><p>DVS（Dynamic Vision Sensor）相机是一种事件驱动的视觉传感器，与传统的帧捕获相机不同，它不捕获连续的图像帧，而是记录每个像素的亮度变化事件。每当像素的亮度变化超过设定的阈值时，DVS相机会生成一个事件，记录下该像素的位置、变化的极性（变亮或变暗）以及时间戳。</p></li><li><p>射线三角形相交检测<br><a href="https://www.cnblogs.com/graphics/archive/2010/08/09/1795348.html">ray triangle intersection test</a></p></li><li><p>关于so3和SO3，se3和SE3之间的指数映射和对数映射的关系，是十分有趣的。想到指数映射，对其计算就是exp的泰勒展开。同时有(反对称矩阵)<br>已知<br>$$ \psi({三维向量}) &#x3D; \theta{a}  其中\theta是模长，a是基方向向量$$</p></li></ul><p>通过<br>$$ a^{\Lambda}a^{\Lambda} &#x3D; aa^{T} - I$$<br>$$ a^{\Lambda}a^{\Lambda}a^{\Lambda} &#x3D; -a^{\Lambda}$$<br>对于<br>$$ e^{so3} &#x3D; SO3$$<br>展开后有<br>$$ exp(\psi^{\Lambda}) &#x3D; exp(\theta a^{\Lambda}) &#x3D; \sum_{n&#x3D;0}^{\infty} \frac{(\theta a^{\Lambda})^n}{n!} &#x3D;cos\theta I + (1-cos\theta)aa^T +sin\theta a^T $$<br>与罗德里格斯公式雷同</p>]]></content>
    
    
    <categories>
      
      <category>SLAM论文</category>
      
      <category>直接法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>基于直接法的事件相机VO</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
